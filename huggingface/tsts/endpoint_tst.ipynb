{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://v3mpasi5ydiiklpc.us-east-1.aws.endpoints.huggingface.cloud\n",
    "curl https://uu149rez6gw9ehej.eu-west-1.aws.endpoints.huggingface.cloud/distilbert-sentiment \\\n",
    "\t-X POST \\\n",
    "\t-d '{\"inputs\": \"Deploying my first endpoint was an amazing experience.\"}' \\\n",
    "\t-H \"Authorization: Bearer <Token>\"\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the endpoint and the token\n",
    "endpoint = \"https://v3mpasi5ydiiklpc.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "token = \"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\"  # Replace with your actual Hugging Face token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Model and tokenizer ID (make sure it's the same as the model in your endpoint)\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  # Replace with your model ID\n",
    "\n",
    "# Load the tokenizer corresponding to your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    \"inputs\": [\n",
    "        \"What is the importance of machine learning?\",\n",
    "        \"How do transformers work in natural language processing?\",\n",
    "        \"Explain the concept of reinforcement learning.\"\n",
    "    ],\n",
    "    \"parameters\": {\n",
    "        \"return_full_text\": False,  # This ensures the prompt isn't included in the response\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in input: 315\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the prompt and count the tokens\n",
    "input_tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
    "num_input_tokens = input_tokens.shape[1]  # Number of tokens in the input\n",
    "print(f\"Number of tokens in input: {num_input_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input data\n",
    "input_data = {\n",
    "\"inputs\": [\"This is input one.\", \"This is input two.\", \"This is input three.\"],\n",
    "  \"parameters\": {\n",
    "        \"return_full_text\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 422 Failed to deserialize the JSON body into the target type: inputs: invalid type: map, expected a string at line 1 column 11\n"
     ]
    }
   ],
   "source": [
    "# Set up the headers, including the authorization token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(endpoint, headers=headers, json=input_data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Print the response from the API\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in response: 100\n",
      "Generated response: \n",
      "\n",
      "-----------------\n",
      "VULNERABLE: YES\n",
      "VULNERABLE_LINES: 1\n",
      "VULNERABILITY_DESCRIPTION: Cross-Site Scripting (XSS)\n",
      "EXPLANATION: The `generateSessionId()` method is not shown, but if it does not properly sanitize user input, it could lead to an XSS vulnerability. An attacker could inject malicious JavaScript into the session ID, which would then be stored in the cookie and executed by the browser.\n",
      "RECOMMENDATIONS: \n",
      "1\n",
      "Total tokens used: 415\n"
     ]
    }
   ],
   "source": [
    "response_json = response.json()\n",
    "\n",
    "# Assuming the response contains the generated text\n",
    "generated_text = response_json[0][\"generated_text\"]\n",
    "\n",
    "# Tokenize the response\n",
    "output_tokens = tokenizer.encode(generated_text, return_tensors='pt')\n",
    "num_output_tokens = output_tokens.shape[1]  # Number of tokens in the response\n",
    "print(f\"Number of tokens in response: {num_output_tokens}\")\n",
    "\n",
    "# Print the generated text and token counts\n",
    "print(\"Generated response:\", generated_text)\n",
    "print(f\"Total tokens used: {num_input_tokens + num_output_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
