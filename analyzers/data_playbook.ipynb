{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      INDEX               TRIAL             PROMPT                    MODEL  \\\n",
      "0         0  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "1         1  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "2         2  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "3         3  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "4         4  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "...     ...                 ...                ...                      ...   \n",
      "5318   5318  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "5319   5319  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "5320   5320  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "5321   5321  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "5322   5322  total_run_shorts_1  prompt_prompt1_v2  llama-3.1-70b-versatile   \n",
      "\n",
      "               SOURCE                                   DATA_ID  \\\n",
      "0     cpython_samples  00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "1     cpython_samples  00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "2     cpython_samples  00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "3     cpython_samples  00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "4     cpython_samples  0b297d4ff1c0e4480ad33acae793fbaf4bf015b4   \n",
      "...               ...                                       ...   \n",
      "5318    linux_samples  958f338e96f874a0d29442396d6adf9c1e17aa2d   \n",
      "5319    linux_samples  958f338e96f874a0d29442396d6adf9c1e17aa2d   \n",
      "5320    linux_samples  958f338e96f874a0d29442396d6adf9c1e17aa2d   \n",
      "5321    linux_samples  95a762e2c8c942780948091f8f2a4f32fce1ac6f   \n",
      "5322    linux_samples  95a762e2c8c942780948091f8f2a4f32fce1ac6f   \n",
      "\n",
      "                    FILENAME  VULN_MODEL  VULN_TRUTH  \n",
      "0           ssl_after.py.txt        True       False  \n",
      "1          ssl_before.py.txt        True        True  \n",
      "2      test_ssl_after.py.txt       False       False  \n",
      "3     test_ssl_before.py.txt       False        True  \n",
      "4       request_after.py.txt        True       False  \n",
      "...                      ...         ...         ...  \n",
      "5318        vmx_before.h.txt       False        True  \n",
      "5319         x86_after.c.txt        True       False  \n",
      "5320        x86_before.c.txt       False        True  \n",
      "5321    verifier_after.c.txt        True       False  \n",
      "5322   verifier_before.c.txt        True        True  \n",
      "\n",
      "[5323 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('groq_outputs_total_run_shorts_1_parsed_outputs.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3032\n",
      "Mismatched: 2291\n"
     ]
    }
   ],
   "source": [
    "countCorrect = ((df['VULN_MODEL']) == (df['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df['VULN_MODEL']) != (df['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3032\n",
      "Mismatched: 2291\n",
      "Total: 5323\n",
      "Score: 56.96036069885403%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"llama-3.1-70b-versatile\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 959\n",
      "Mismatched: 226\n",
      "Total: 1185\n",
      "Score: 80.9282700421941%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"llama-3.1-70b-versatile\") & (df[\"SOURCE\"] == \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 234\n",
      "Mismatched: 258\n",
      "Total: 492\n",
      "Score: 47.5609756097561%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"llama-3.1-70b-versatile\") & (df[\"SOURCE\"] == \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 0\n",
      "Mismatched: 0\n",
      "Total: 0\n",
      "Score: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_15304\\765826503.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(f\"Score: {countCorrect/len(df_gemma)*100}%\")\n"
     ]
    }
   ],
   "source": [
    "df_gemma = df[df[\"MODEL\"] == \"gemma2-9b-it\" ]\n",
    "countCorrect = ((df_gemma['VULN_MODEL']) == (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_gemma['VULN_MODEL']) != (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_gemma)}')\n",
    "print(f\"Score: {countCorrect/len(df_gemma)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 PROMPT           SOURCE  \\\n",
      "0     prompt_prompt1_v2  cpython_samples   \n",
      "1     prompt_prompt1_v2  cpython_samples   \n",
      "2     prompt_prompt1_v2  cpython_samples   \n",
      "3     prompt_prompt1_v2  cpython_samples   \n",
      "4     prompt_prompt1_v2  cpython_samples   \n",
      "...                 ...              ...   \n",
      "5318  prompt_prompt1_v2    linux_samples   \n",
      "5319  prompt_prompt1_v2    linux_samples   \n",
      "5320  prompt_prompt1_v2    linux_samples   \n",
      "5321  prompt_prompt1_v2    linux_samples   \n",
      "5322  prompt_prompt1_v2    linux_samples   \n",
      "\n",
      "                                       DATA_ID                FILENAME  \\\n",
      "0     00464bbed66e5f64bdad7f930b315a88d5afccae        ssl_after.py.txt   \n",
      "1     00464bbed66e5f64bdad7f930b315a88d5afccae       ssl_before.py.txt   \n",
      "2     00464bbed66e5f64bdad7f930b315a88d5afccae   test_ssl_after.py.txt   \n",
      "3     00464bbed66e5f64bdad7f930b315a88d5afccae  test_ssl_before.py.txt   \n",
      "4     0b297d4ff1c0e4480ad33acae793fbaf4bf015b4    request_after.py.txt   \n",
      "...                                        ...                     ...   \n",
      "5318  958f338e96f874a0d29442396d6adf9c1e17aa2d        vmx_before.h.txt   \n",
      "5319  958f338e96f874a0d29442396d6adf9c1e17aa2d         x86_after.c.txt   \n",
      "5320  958f338e96f874a0d29442396d6adf9c1e17aa2d        x86_before.c.txt   \n",
      "5321  95a762e2c8c942780948091f8f2a4f32fce1ac6f    verifier_after.c.txt   \n",
      "5322  95a762e2c8c942780948091f8f2a4f32fce1ac6f   verifier_before.c.txt   \n",
      "\n",
      "      VULN_TRUTH  llama-3.1-70b-versatile  \n",
      "0          False                     True  \n",
      "1           True                     True  \n",
      "2          False                    False  \n",
      "3           True                    False  \n",
      "4          False                     True  \n",
      "...          ...                      ...  \n",
      "5318        True                    False  \n",
      "5319       False                     True  \n",
      "5320        True                    False  \n",
      "5321       False                     True  \n",
      "5322        True                     True  \n",
      "\n",
      "[5323 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by the relevant columns\n",
    "grouped = df.groupby(['PROMPT', 'SOURCE', 'DATA_ID', 'FILENAME'])\n",
    "\n",
    "# Create a list to hold the final rows\n",
    "final_rows = []\n",
    "\n",
    "# Iterate over each group to create the consolidated rows\n",
    "for name, group in grouped:\n",
    "    new_row = {\n",
    "        'PROMPT': name[0],\n",
    "        'SOURCE': name[1],\n",
    "        'DATA_ID': name[2],\n",
    "        'FILENAME': name[3],\n",
    "        'VULN_TRUTH': group['VULN_TRUTH'].iloc[0]\n",
    "    }\n",
    "    \n",
    "    # Add each model's VULN_MODEL value to the row\n",
    "    for _, row in group.iterrows():\n",
    "        new_row[row['MODEL']] = row['VULN_MODEL']\n",
    "    \n",
    "    final_rows.append(new_row)\n",
    "\n",
    "# Convert the list of rows into a new DataFrame\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered DataFrame where VULN_MODEL values don't match:\n",
      "              PROMPT       SOURCE DATA_ID             FILENAME  VULN_TRUTH  \\\n",
      "5     prompt_prompt1  cwe_samples    1004   1004_Good.java.txt       False   \n",
      "19    prompt_prompt1  cwe_samples    1041   1041_Good.java.txt       False   \n",
      "32    prompt_prompt1  cwe_samples    1071  1071_Bad_1.java.txt        True   \n",
      "38    prompt_prompt1  cwe_samples     110     110_Bad.java.txt        True   \n",
      "46    prompt_prompt1  cwe_samples     112   112_Bad_1.java.txt        True   \n",
      "...              ...          ...     ...                  ...         ...   \n",
      "1123  prompt_prompt1  cwe_samples     862      862_Bad.php.txt        True   \n",
      "1136  prompt_prompt1  cwe_samples     908     908_Bad.java.txt        True   \n",
      "1139  prompt_prompt1  cwe_samples     908       908_Good.c.txt       False   \n",
      "1145  prompt_prompt1  cwe_samples     909       909_Good.c.txt       False   \n",
      "1148  prompt_prompt1  cwe_samples     915       915_Bad.js.txt        True   \n",
      "\n",
      "      llama-3.1-70b-versatile gemma2-9b-it  \n",
      "5                        True        False  \n",
      "19                       True        False  \n",
      "32                       True        False  \n",
      "38                       True        False  \n",
      "46                       True        False  \n",
      "...                       ...          ...  \n",
      "1123                     True        False  \n",
      "1136                    False         True  \n",
      "1139                     True        False  \n",
      "1145                     True        False  \n",
      "1148                     True        False  \n",
      "\n",
      "[95 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where any of the VULN_MODEL values don't match\n",
    "model_columns = final_df.columns.difference(['PROMPT', 'SOURCE', 'DATA_ID', 'FILENAME', 'VULN_TRUTH'])\n",
    "\n",
    "# Filtering condition: count unique values in non-NaN entries, include row if more than 1 unique value\n",
    "filtered_df = final_df[final_df[model_columns].apply(lambda row: row.dropna().nunique() > 1, axis=1)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"\\nFiltered DataFrame where VULN_MODEL values don't match:\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
