{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      INDEX        TRIAL          PROMPT                    MODEL  \\\n",
      "0         0  total_run_1  prompt_prompt1             gemma2-9b-it   \n",
      "1         1  total_run_1  prompt_prompt1             gemma2-9b-it   \n",
      "2         2  total_run_1  prompt_prompt1             gemma2-9b-it   \n",
      "3         3  total_run_1  prompt_prompt1             gemma2-9b-it   \n",
      "4         4  total_run_1  prompt_prompt1             gemma2-9b-it   \n",
      "...     ...          ...             ...                      ...   \n",
      "2368   2368  total_run_1  prompt_prompt1  llama-3.1-70b-versatile   \n",
      "2369   2369  total_run_1  prompt_prompt1  llama-3.1-70b-versatile   \n",
      "2370   2370  total_run_1  prompt_prompt1  llama-3.1-70b-versatile   \n",
      "2371   2371  total_run_1  prompt_prompt1  llama-3.1-70b-versatile   \n",
      "2372   2372  total_run_1  prompt_prompt1  llama-3.1-70b-versatile   \n",
      "\n",
      "           SOURCE DATA_ID            FILENAME  VULN_MODEL  VULN_TRUTH  \n",
      "0     cwe_samples    1004   1004_Bad.java.txt        True        True  \n",
      "1     cwe_samples    1004  1004_Good.java.txt       False       False  \n",
      "2     cwe_samples     102     102_Bad.xml.txt        True        True  \n",
      "3     cwe_samples    1022   1022_Bad.html.txt        True        True  \n",
      "4     cwe_samples    1022     1022_Bad.js.txt        True        True  \n",
      "...           ...     ...                 ...         ...         ...  \n",
      "2368  cwe_samples      95      95_Good.py.txt        True       False  \n",
      "2369  cwe_samples      96      96_Bad.php.txt        True        True  \n",
      "2370  cwe_samples      98      98_Bad.php.txt        True        True  \n",
      "2371  cwe_samples      99      99_Bad.cpp.txt        True        True  \n",
      "2372  cwe_samples      99     99_Bad.java.txt        True        True  \n",
      "\n",
      "[2373 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('total_run_1_parsed_outputs.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1931\n",
      "Mismatched: 442\n"
     ]
    }
   ],
   "source": [
    "countCorrect = ((df['VULN_MODEL']) == (df['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df['VULN_MODEL']) != (df['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 969\n",
      "Mismatched: 220\n",
      "Total: 1189\n",
      "Score: 81.49705634987384%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[df[\"MODEL\"] == \"llama-3.1-70b-versatile\" ]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 962\n",
      "Mismatched: 222\n",
      "Total: 1184\n",
      "Score: 81.25%\n"
     ]
    }
   ],
   "source": [
    "df_gemma = df[df[\"MODEL\"] == \"gemma2-9b-it\" ]\n",
    "countCorrect = ((df_gemma['VULN_MODEL']) == (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_gemma['VULN_MODEL']) != (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_gemma)}')\n",
    "print(f\"Score: {countCorrect/len(df_gemma)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
