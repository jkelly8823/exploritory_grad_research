{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INDEX              TRIAL          PROMPT  \\\n",
      "0          0  total_run_context  prompt_context   \n",
      "1          1  total_run_context  prompt_context   \n",
      "2          2  total_run_context  prompt_context   \n",
      "3          3  total_run_context  prompt_context   \n",
      "4          4  total_run_context  prompt_context   \n",
      "...      ...                ...             ...   \n",
      "27619  27619  total_run_context  prompt_context   \n",
      "27620  27620  total_run_context  prompt_context   \n",
      "27621  27621  total_run_context  prompt_context   \n",
      "27622  27622  total_run_context  prompt_context   \n",
      "27623  27623  total_run_context  prompt_context   \n",
      "\n",
      "                                       MODEL           SOURCE  \\\n",
      "0                       google_gemma-2-9b-it  cpython_samples   \n",
      "1                       google_gemma-2-9b-it  cpython_samples   \n",
      "2                       google_gemma-2-9b-it  cpython_samples   \n",
      "3                       google_gemma-2-9b-it  cpython_samples   \n",
      "4                       google_gemma-2-9b-it  cpython_samples   \n",
      "...                                      ...              ...   \n",
      "27619  meta-llama_Meta-Llama-3.1-8B-Instruct    react_samples   \n",
      "27620  meta-llama_Meta-Llama-3.1-8B-Instruct    react_samples   \n",
      "27621  meta-llama_Meta-Llama-3.1-8B-Instruct    react_samples   \n",
      "27622  meta-llama_Meta-Llama-3.1-8B-Instruct    react_samples   \n",
      "27623  meta-llama_Meta-Llama-3.1-8B-Instruct    react_samples   \n",
      "\n",
      "                                        DATA_ID                 FILENAME  \\\n",
      "0      00464bbed66e5f64bdad7f930b315a88d5afccae         ssl_after.py.txt   \n",
      "1      00464bbed66e5f64bdad7f930b315a88d5afccae        ssl_before.py.txt   \n",
      "2      00464bbed66e5f64bdad7f930b315a88d5afccae    test_ssl_after.py.txt   \n",
      "3      00464bbed66e5f64bdad7f930b315a88d5afccae   test_ssl_before.py.txt   \n",
      "4      0b297d4ff1c0e4480ad33acae793fbaf4bf015b4     request_after.py.txt   \n",
      "...                                         ...                      ...   \n",
      "27619  8d87e374ac69904012530af702af1cd51d90e07d  package_before.json.txt   \n",
      "27620  c325aec1ee5ae970ea70efc9b19574aa0e72c9a1      yarn_after.lock.txt   \n",
      "27621  c325aec1ee5ae970ea70efc9b19574aa0e72c9a1     yarn_before.lock.txt   \n",
      "27622  d7b45ec9b765575e63e034fb7d844027a323b06c      yarn_after.lock.txt   \n",
      "27623  d7b45ec9b765575e63e034fb7d844027a323b06c     yarn_before.lock.txt   \n",
      "\n",
      "       VULN_MODEL  VULN_TRUTH  \n",
      "0           False       False  \n",
      "1           False        True  \n",
      "2           False       False  \n",
      "3           False        True  \n",
      "4            True       False  \n",
      "...           ...         ...  \n",
      "27619       False        True  \n",
      "27620        True       False  \n",
      "27621        True        True  \n",
      "27622       False       False  \n",
      "27623        True        True  \n",
      "\n",
      "[27624 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('huggingface_outputs_total_run_context_parsed_outputs.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 14655\n",
      "Mismatched: 12969\n",
      "Total: 27624\n",
      "Score: 53.051694178974806%\n"
     ]
    }
   ],
   "source": [
    "countCorrect = ((df['VULN_MODEL']) == (df['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df['VULN_MODEL']) != (df['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {countCorrect + countFalse}')\n",
    "print(f\"Score: {countCorrect/(countCorrect+countFalse)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4886\n",
      "Mismatched: 4322\n",
      "Total: 9208\n",
      "Score: 53.06255430060817%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"meta-llama_Meta-Llama-3.1-8B-Instruct\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 977\n",
      "Mismatched: 208\n",
      "Total: 1185\n",
      "Score: 82.44725738396625%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"meta-llama_Meta-Llama-3.1-8B-Instruct\") & (df[\"SOURCE\"] == \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3909\n",
      "Mismatched: 4114\n",
      "Total: 8023\n",
      "Score: 48.722423033777886%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"meta-llama_Meta-Llama-3.1-8B-Instruct\") & (df[\"SOURCE\"] != \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4827\n",
      "Mismatched: 4373\n",
      "Total: 9200\n",
      "Score: 52.46739130434782%\n"
     ]
    }
   ],
   "source": [
    "# df_gemma = df[df[\"MODEL\"] == \"gemma2-9b-it\" ]\n",
    "df_gemma = df[df[\"MODEL\"] == \"google_gemma-2-9b-it\" ]\n",
    "countCorrect = ((df_gemma['VULN_MODEL']) == (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_gemma['VULN_MODEL']) != (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_gemma)}')\n",
    "print(f\"Score: {countCorrect/len(df_gemma)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 871\n",
      "Mismatched: 314\n",
      "Total: 1185\n",
      "Score: 73.50210970464136%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"google_gemma-2-9b-it\") & (df[\"SOURCE\"] == \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3956\n",
      "Mismatched: 4059\n",
      "Total: 8015\n",
      "Score: 49.357454772301935%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"google_gemma-2-9b-it\") & (df[\"SOURCE\"] != \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4942\n",
      "Mismatched: 4274\n",
      "Total: 9216\n",
      "Score: 53.62413194444444%\n"
     ]
    }
   ],
   "source": [
    "df_gemma = df[df[\"MODEL\"] == \"LeroyDyer_Mixtral_AI_CyberCoder_7b\" ]\n",
    "countCorrect = ((df_gemma['VULN_MODEL']) == (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_gemma['VULN_MODEL']) != (df_gemma['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_gemma)}')\n",
    "print(f\"Score: {countCorrect/len(df_gemma)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 966\n",
      "Mismatched: 219\n",
      "Total: 1185\n",
      "Score: 81.51898734177216%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"LeroyDyer_Mixtral_AI_CyberCoder_7b\") & (df[\"SOURCE\"] == \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 3976\n",
      "Mismatched: 4055\n",
      "Total: 8031\n",
      "Score: 49.50815589590337%\n"
     ]
    }
   ],
   "source": [
    "df_llama = df[(df[\"MODEL\"] == \"LeroyDyer_Mixtral_AI_CyberCoder_7b\") & (df[\"SOURCE\"] != \"cwe_samples\")]\n",
    "countCorrect = ((df_llama['VULN_MODEL']) == (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Correct: {countCorrect}')\n",
    "countFalse = ((df_llama['VULN_MODEL']) != (df_llama['VULN_TRUTH'])).sum()\n",
    "print(f'Mismatched: {countFalse}')\n",
    "print(f'Total: {len(df_llama)}')\n",
    "print(f\"Score: {countCorrect/len(df_llama)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              PROMPT           SOURCE  \\\n",
      "0     prompt_context  cpython_samples   \n",
      "1     prompt_context  cpython_samples   \n",
      "2     prompt_context  cpython_samples   \n",
      "3     prompt_context  cpython_samples   \n",
      "4     prompt_context  cpython_samples   \n",
      "...              ...              ...   \n",
      "9215  prompt_context    react_samples   \n",
      "9216  prompt_context    react_samples   \n",
      "9217  prompt_context    react_samples   \n",
      "9218  prompt_context    react_samples   \n",
      "9219  prompt_context    react_samples   \n",
      "\n",
      "                                       DATA_ID                 FILENAME  \\\n",
      "0     00464bbed66e5f64bdad7f930b315a88d5afccae         ssl_after.py.txt   \n",
      "1     00464bbed66e5f64bdad7f930b315a88d5afccae        ssl_before.py.txt   \n",
      "2     00464bbed66e5f64bdad7f930b315a88d5afccae    test_ssl_after.py.txt   \n",
      "3     00464bbed66e5f64bdad7f930b315a88d5afccae   test_ssl_before.py.txt   \n",
      "4     0b297d4ff1c0e4480ad33acae793fbaf4bf015b4     request_after.py.txt   \n",
      "...                                        ...                      ...   \n",
      "9215  8d87e374ac69904012530af702af1cd51d90e07d  package_before.json.txt   \n",
      "9216  c325aec1ee5ae970ea70efc9b19574aa0e72c9a1      yarn_after.lock.txt   \n",
      "9217  c325aec1ee5ae970ea70efc9b19574aa0e72c9a1     yarn_before.lock.txt   \n",
      "9218  d7b45ec9b765575e63e034fb7d844027a323b06c      yarn_after.lock.txt   \n",
      "9219  d7b45ec9b765575e63e034fb7d844027a323b06c     yarn_before.lock.txt   \n",
      "\n",
      "      VULN_TRUTH google_gemma-2-9b-it LeroyDyer_Mixtral_AI_CyberCoder_7b  \\\n",
      "0          False                False                               True   \n",
      "1           True                False                               True   \n",
      "2          False                False                               True   \n",
      "3           True                False                               True   \n",
      "4          False                 True                               True   \n",
      "...          ...                  ...                                ...   \n",
      "9215        True                 True                              False   \n",
      "9216       False                 True                               True   \n",
      "9217        True                 True                               True   \n",
      "9218       False                False                              False   \n",
      "9219        True                False                              False   \n",
      "\n",
      "     meta-llama_Meta-Llama-3.1-8B-Instruct  \n",
      "0                                    False  \n",
      "1                                     True  \n",
      "2                                     True  \n",
      "3                                     True  \n",
      "4                                     True  \n",
      "...                                    ...  \n",
      "9215                                 False  \n",
      "9216                                  True  \n",
      "9217                                  True  \n",
      "9218                                 False  \n",
      "9219                                  True  \n",
      "\n",
      "[9220 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by the relevant columns\n",
    "grouped = df.groupby(['PROMPT', 'SOURCE', 'DATA_ID', 'FILENAME'])\n",
    "\n",
    "# Create a list to hold the final rows\n",
    "final_rows = []\n",
    "\n",
    "# Iterate over each group to create the consolidated rows\n",
    "for name, group in grouped:\n",
    "    new_row = {\n",
    "        'PROMPT': name[0],\n",
    "        'SOURCE': name[1],\n",
    "        'DATA_ID': name[2],\n",
    "        'FILENAME': name[3],\n",
    "        'VULN_TRUTH': group['VULN_TRUTH'].iloc[0]\n",
    "    }\n",
    "    \n",
    "    # Add each model's VULN_MODEL value to the row\n",
    "    for _, row in group.iterrows():\n",
    "        new_row[row['MODEL']] = row['VULN_MODEL']\n",
    "    \n",
    "    final_rows.append(new_row)\n",
    "\n",
    "# Convert the list of rows into a new DataFrame\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered DataFrame where VULN_MODEL values don't match:\n",
      "              PROMPT           SOURCE  \\\n",
      "0     prompt_context  cpython_samples   \n",
      "1     prompt_context  cpython_samples   \n",
      "2     prompt_context  cpython_samples   \n",
      "3     prompt_context  cpython_samples   \n",
      "6     prompt_context  cpython_samples   \n",
      "...              ...              ...   \n",
      "9206  prompt_context    rails_samples   \n",
      "9211  prompt_context    react_samples   \n",
      "9213  prompt_context    react_samples   \n",
      "9215  prompt_context    react_samples   \n",
      "9219  prompt_context    react_samples   \n",
      "\n",
      "                                       DATA_ID  \\\n",
      "0     00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "1     00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "2     00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "3     00464bbed66e5f64bdad7f930b315a88d5afccae   \n",
      "6     0b297d4ff1c0e4480ad33acae793fbaf4bf015b4   \n",
      "...                                        ...   \n",
      "9206  fee0bc57385b564b2789d199969ac26409603188   \n",
      "9211  1434af3d228e216366bd4b7dd324c6408087b3df   \n",
      "9213  8287cb92903fdfc983dcc8deecd8293402fc3bd4   \n",
      "9215  8d87e374ac69904012530af702af1cd51d90e07d   \n",
      "9219  d7b45ec9b765575e63e034fb7d844027a323b06c   \n",
      "\n",
      "                              FILENAME  VULN_TRUTH google_gemma-2-9b-it  \\\n",
      "0                     ssl_after.py.txt       False                False   \n",
      "1                    ssl_before.py.txt        True                False   \n",
      "2                test_ssl_after.py.txt       False                False   \n",
      "3               test_ssl_before.py.txt        True                False   \n",
      "6            test_urllib2_after.py.txt       False                False   \n",
      "...                                ...         ...                  ...   \n",
      "9206  http_authentication_after.rb.txt       False                False   \n",
      "9211           package_before.json.txt        True                False   \n",
      "9213           package_before.json.txt        True                 True   \n",
      "9215           package_before.json.txt        True                 True   \n",
      "9219              yarn_before.lock.txt        True                False   \n",
      "\n",
      "     LeroyDyer_Mixtral_AI_CyberCoder_7b meta-llama_Meta-Llama-3.1-8B-Instruct  \n",
      "0                                  True                                 False  \n",
      "1                                  True                                  True  \n",
      "2                                  True                                  True  \n",
      "3                                  True                                  True  \n",
      "6                                  True                                  True  \n",
      "...                                 ...                                   ...  \n",
      "9206                               True                                  True  \n",
      "9211                              False                                  True  \n",
      "9213                              False                                 False  \n",
      "9215                              False                                 False  \n",
      "9219                              False                                  True  \n",
      "\n",
      "[6434 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where any of the VULN_MODEL values don't match\n",
    "model_columns = final_df.columns.difference(['PROMPT', 'SOURCE', 'DATA_ID', 'FILENAME', 'VULN_TRUTH'])\n",
    "\n",
    "# Filtering condition: count unique values in non-NaN entries, include row if more than 1 unique value\n",
    "filtered_df = final_df[final_df[model_columns].apply(lambda row: row.dropna().nunique() > 1, axis=1)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"\\nFiltered DataFrame where VULN_MODEL values don't match:\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
